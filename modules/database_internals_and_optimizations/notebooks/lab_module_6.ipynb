{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ccbd277",
   "metadata": {},
   "source": [
    "# Module 6: The Cost-Based Optimizer (CBO)\n",
    "## Goal: Shatter the illusion that the database \"knows\" everything.\n",
    "\n",
    "In previous chapters, we learned about the physical reality of disks (Seek vs. Scan) and indexing (B-Trees). But who decides whether to use that B-Tree or just scan the whole disk?\n",
    "\n",
    "Meet **The Optimizer**.\n",
    "\n",
    "The Optimizer is the \"Brain\" of the database. It is not magic; it is a mathematician running an auction. Before every query, it looks at available paths (Index Scan, Seq Scan, Bitmap Scan), estimates the \"Cost\" of each based on stored statistics, and picks the cheapest one.\n",
    "\n",
    "**The catch?** It doesn't look at the actual data. It looks at a *summary* of the data (Statistics). If the summary is wrong, the Optimizer hallucinates.\n",
    "\n",
    "### The Physics of Data\n",
    "1.  **Statistics (The Map):** The DB stores histograms and row counts in a separate metadata table.\n",
    "2.  **Cost (The Currency):** The DB assigns a generic \"cost unit\" to every operation (e.g., Reading a page = 1.0, Processing a row = 0.01).\n",
    "3.  **Plan Stability:** Once a plan is picked, the DB follows it blindly, even if it leads to a cliff.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac202c0a",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Setup and Connection\n",
    "\n",
    "We will use **PostgreSQL** for this module, as it has a robust and transparent Cost-Based Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Database Connection Parameters\n",
    "DB_PARAMS = {\n",
    "    \"host\": \"db_int_opt\",\n",
    "    \"port\": 5432,\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"password\",\n",
    "    \"dbname\": \"db_int_opt\"\n",
    "}\n",
    "\n",
    "def get_db_connection():\n",
    "    conn = psycopg2.connect(**DB_PARAMS)\n",
    "    conn.autocommit = True\n",
    "    return conn\n",
    "\n",
    "print(\"✅ Connected to Postgres.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab011e",
   "metadata": {},
   "source": [
    "## 2. Experiment 6.1: The Statistics (Histograms)\n",
    "How does the database know that `PREMIUM` users are rare (5%) but `ACTIVE` users are common (70%) without counting them?\n",
    "\n",
    "It uses Histograms. We will load your specific `users` data and see if the database can predict the skew.\n",
    "\n",
    "#### Step 1: Prepare the Data\n",
    "We load `users.csv` into Postgres and explicitly run `ANALYZE` to build the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7bd3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iconn = get_db_connection()\n",
    "cur = conn.cursor()\n",
    "\n",
    "# 1. Create table matching your file schema\n",
    "cur.execute(\"DROP TABLE IF EXISTS users_stats;\")\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE users_stats (\n",
    "        user_id INTEGER,\n",
    "        name TEXT,\n",
    "        email TEXT,\n",
    "        account_status VARCHAR(20),\n",
    "        signup_date TIMESTAMP,\n",
    "        is_email_verified BOOLEAN\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# 2. Load data\n",
    "print(\"⏳ Loading users.csv into Postgres...\")\n",
    "df = pd.read_csv('../data/users.csv')\n",
    "\n",
    "# Efficient Bulk Insert\n",
    "buffer = StringIO()\n",
    "df.to_csv(buffer, index=False, header=False)\n",
    "buffer.seek(0)\n",
    "cur.copy_expert(\"COPY users_stats FROM STDIN WITH CSV\", buffer)\n",
    "\n",
    "# 3. CRITICAL STEP: Force the Database to study the data\n",
    "cur.execute(\"ANALYZE users_stats;\")\n",
    "print(\"✅ Data Loaded and Analyzed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e942e291",
   "metadata": {},
   "source": [
    "## Step 2: The Prediction Test\n",
    "We will ask the database to **explain** two queries. We won't run them; we just want the Plan Rows (The Estimate).\n",
    "1. `SELECT * FROM users_stats WHERE account_status = 'ACTIVE'`\n",
    "2. `SELECT * FROM users_stats WHERE account_status = 'PREMIUM'`\n",
    "\n",
    "**Hypothesis**: If the DB is smart, it should predict a higher number for 'ACTIVE' than 'PREMIUM', even though the query looks identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimate(status_value):\n",
    "    query = f\"EXPLAIN (FORMAT JSON) SELECT * FROM users_stats WHERE account_status = '{status_value}'\"\n",
    "    cur.execute(query)\n",
    "    plan = cur.fetchone()[0][0]['Plan']\n",
    "    return plan['Plan Rows']\n",
    "\n",
    "# Get estimates from the Optimizer\n",
    "est_active = get_estimate('ACTIVE')\n",
    "est_premium = get_estimate('PREMIUM')\n",
    "\n",
    "# Get actuals (Ground Truth) from the Disk\n",
    "cur.execute(\"SELECT count(*) FROM users_stats WHERE account_status = 'ACTIVE'\")\n",
    "real_active = cur.fetchone()[0]\n",
    "\n",
    "cur.execute(\"SELECT count(*) FROM users_stats WHERE account_status = 'PREMIUM'\")\n",
    "real_premium = cur.fetchone()[0]\n",
    "\n",
    "print(f\"ACTIVE  (Majority) -> Estimated: {est_active}, Actual: {real_active}\")\n",
    "print(f\"PREMIUM (Minority) -> Estimated: {est_premium},   Actual: {real_premium}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ace50",
   "metadata": {},
   "source": [
    "### Step 3: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c865943",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['ACTIVE', 'PREMIUM']\n",
    "estimates = [est_active, est_premium]\n",
    "actuals = [real_active, real_premium]\n",
    "\n",
    "x = range(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bar1 = ax.bar([i - width/2 for i in x], estimates, width, label='Optimizer Estimate', color='skyblue')\n",
    "bar2 = ax.bar([i + width/2 for i in x], actuals, width, label='Actual Rows', color='salmon')\n",
    "\n",
    "ax.set_ylabel('Row Count')\n",
    "ax.set_title('Experiment 6.1: Can the DB see the Skew?')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55fc88b",
   "metadata": {},
   "source": [
    "#### Step 4: Analysis\n",
    "Look at how closely the Blue Bar (what the database thought it had) matches the Red Bar (what it actually had).\n",
    "1. **The Skew is Visible**: The database correctly knows that ACTIVE users are the vast majority (~70k) and PREMIUM users are a tiny minority (~5k).\n",
    "2. **The Accuracy**:\n",
    "    - **Active**: Estimated 70,097 vs Actual 70,111 (99.9% accuracy).\n",
    "    - **Premium**: Estimated 4,967 vs Actual 4,871 (98% accuracy).\n",
    "\n",
    "**What does this prove?**\n",
    "It proves that the Cost-Based Optimizer (CBO) is not guessing blindly. When you ran the `ANALYZE` command in the setup, the database built a statistical \"Map\" of your data.\n",
    "\n",
    "**The Lesson**: The database didn't actually count the rows to give you that blue bar. It looked at its \"cheat sheet\" (Histogram) and said, \"Based on my last survey, I expect to find about 70,097 rows.\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3323b",
   "metadata": {},
   "source": [
    "## 3. Experiment 6.2: The Auction (Comparing Paths)\n",
    "The CBO uses \"Cost\" to decide between strategies.\n",
    "- **Sequential Scan**: Good for `ACTIVE` users (reading 70% of the disk).\n",
    "- **Index Scan**: Good for `PREMIUM` users (reading 5% of the disk).\n",
    "\n",
    "We will force the database to use the wrong method for `ACTIVE` users and measure the penalty.\n",
    "\n",
    "##### Step 1: Setup Indices\n",
    "We'll use the same `users_stats` table but add an index on `account_status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ac390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create Index\n",
    "print(\"⏳ Building Index on account_status...\")\n",
    "cur.execute(\"CREATE INDEX idx_status ON users_stats(account_status);\")\n",
    "cur.execute(\"ANALYZE users_stats;\")\n",
    "print(\"✅ Index Built.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e80feeb",
   "metadata": {},
   "source": [
    "#### Step 2: The \"Tipping Point\"\n",
    "We query for `ACTIVE` users.\n",
    "- **Hypothesis**: Reading 70k rows via Index (Random I/O) is slower than reading the whole file (Seq I/O)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT count(*) FROM users_stats WHERE account_status = 'ACTIVE'\"\n",
    "\n",
    "# 1. Run with CBO's Natural Choice (Should be Seq Scan)\n",
    "cur.execute(\"SET enable_seqscan = ON;\")\n",
    "cur.execute(\"SET enable_indexscan = ON;\") \n",
    "start_nat = time.time()\n",
    "cur.execute(f\"EXPLAIN (ANALYZE, FORMAT JSON) {query}\")\n",
    "result_nat = cur.fetchone()[0][0]\n",
    "end_nat = time.time()\n",
    "\n",
    "cost_nat = result_nat['Plan']['Total Cost']\n",
    "time_nat = (end_nat - start_nat) * 1000 # ms\n",
    "algo_nat = result_nat['Plan']['Node Type']\n",
    "\n",
    "# 2. Force the Bad Choice (Index Scan for 70% of data)\n",
    "cur.execute(\"SET enable_seqscan = OFF;\") # DISABLE Seq Scan\n",
    "start_bad = time.time()\n",
    "cur.execute(f\"EXPLAIN (ANALYZE, FORMAT JSON) {query}\")\n",
    "result_bad = cur.fetchone()[0][0]\n",
    "end_bad = time.time()\n",
    "\n",
    "cost_bad = result_bad['Plan']['Total Cost']\n",
    "time_bad = (end_bad - start_bad) * 1000 # ms\n",
    "algo_bad = result_bad['Plan']['Node Type']\n",
    "\n",
    "# Reset\n",
    "cur.execute(\"SET enable_seqscan = ON;\")\n",
    "\n",
    "print(f\"Natural ({algo_nat}): Cost={cost_nat:.2f}, Time={time_nat:.2f}ms\")\n",
    "print(f\"Forced  ({algo_bad}): Cost={cost_bad:.2f}, Time={time_bad:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052ca89d",
   "metadata": {},
   "source": [
    "#### Step 3: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c425eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [f\"Natural\\n({algo_nat})\", f\"Forced\\n({algo_bad})\"]\n",
    "times = [time_nat, time_bad]\n",
    "costs = [cost_nat, cost_bad]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Chart 1: Execution Time (Reality)\n",
    "sns.barplot(x=methods, y=times, ax=ax1, palette=[\"green\", \"red\"])\n",
    "ax1.set_title(\"Actual Execution Time (ms)\")\n",
    "ax1.set_ylabel(\"Milliseconds\")\n",
    "\n",
    "# Chart 2: Optimizer Cost (Prediction)\n",
    "sns.barplot(x=methods, y=costs, ax=ax2, palette=[\"green\", \"red\"])\n",
    "ax2.set_title(\"Optimizer 'Cost' Units (Prediction)\")\n",
    "ax2.set_ylabel(\"Cost Units\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ebc9e5",
   "metadata": {},
   "source": [
    "#### Step 4: Analysis\n",
    "\n",
    "**Why did the Optimizer fail?**\n",
    "You have encountered The RAM Illusion.\n",
    "\n",
    "The Optimizer's cost model is conservative; it assumes the data is cold and sitting on a slow disk. It penalizes \"Random I/O\" (Index Scans) heavily because moving a mechanical disk head takes ~5-10ms.\n",
    "\n",
    "**However**: Your dataset (100k rows) is tiny.\n",
    "- The entire table fits into the Docker container's RAM (Memory).\n",
    "- \"Seeking\" in RAM takes nanoseconds, not milliseconds.\n",
    "- Because the penalty for seeking vanished, the overhead of the Index Scan disappeared, and it beat the Sequential Scan.\n",
    "\n",
    "#### The \"Senior Architect\" Lesson\n",
    "If this table were 100 GB instead of 10 MB:\n",
    "- The Right Chart (Prediction) would look exactly the same.\n",
    "- The Left Chart (Reality) would flip. The Red bar (Index Scan) would be 100x taller than the Green bar, because the disk would be thrashing back and forth trying to read 70% of the data randomly.\n",
    "\n",
    "**Conclusion for this Lab**: You have proven that Performance is context-dependent. The Optimizer made the \"safe\" choice for a scalable system, even if it wasn't the absolute fastest choice for this tiny, cached dataset.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2fd9b",
   "metadata": {},
   "source": [
    "## 4. Experiment 6.3: When the Optimizer Lies (Stale Stats)\n",
    "The Optimizer relies on `pg_stats`. If we delete data but don't tell the database, the map is wrong.\n",
    "\n",
    "#### Step 1: Create Stale Scenario\n",
    "We will create a fresh table, analyze it, then delete 90% of the data (all the `ACTIVE` users)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Table\n",
    "cur.execute(\"DROP TABLE IF EXISTS stale_demo;\")\n",
    "cur.execute(\"CREATE TABLE stale_demo AS SELECT * FROM users_stats;\")\n",
    "cur.execute(\"ANALYZE stale_demo;\") # Fresh stats\n",
    "\n",
    "# 2. Get Initial Estimate\n",
    "cur.execute(\"EXPLAIN (FORMAT JSON) SELECT * FROM stale_demo;\")\n",
    "initial_est = cur.fetchone()[0][0]['Plan']['Plan Rows']\n",
    "\n",
    "# 3. The Purge (Delete all ACTIVE users)\n",
    "# NOTE: We are NOT running ANALYZE after this.\n",
    "cur.execute(\"DELETE FROM stale_demo WHERE account_status = 'ACTIVE';\") \n",
    "\n",
    "# 4. Get Stale Estimate\n",
    "cur.execute(\"EXPLAIN (FORMAT JSON) SELECT * FROM stale_demo;\")\n",
    "stale_est = cur.fetchone()[0][0]['Plan']['Plan Rows']\n",
    "\n",
    "# 5. Get Real Count\n",
    "cur.execute(\"SELECT count(*) FROM stale_demo;\")\n",
    "real_count = cur.fetchone()[0]\n",
    "\n",
    "print(f\"Initial Estimate: {initial_est}\")\n",
    "print(f\"Stale Estimate:   {stale_est} (The Lie)\")\n",
    "print(f\"Actual Rows:      {real_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17203f",
   "metadata": {},
   "source": [
    "#### Step 2: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df861f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Before Delete (Est)', 'After Delete (Est)', 'After Delete (Actual)']\n",
    "values = [initial_est, stale_est, real_count]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(labels, values, color=['gray', 'red', 'green'])\n",
    "plt.title('Experiment 6.3: The Stale Statistics Problem')\n",
    "plt.ylabel('Row Count')\n",
    "\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c4f79",
   "metadata": {},
   "source": [
    "### Step 3: Analysis\n",
    "**The Hallucination**: The database still thinks it has 100k rows (Red Bar), even though you deleted 70k of them (Green Bar).\n",
    "\n",
    "**Why this matters**: If you run a Join now, the database will reserve memory for 100k rows. Since only ~30k exist, that memory is wasted. Conversely, if you added 1M rows but the DB thought you had 100, it would reserve too little memory, forcing the join to spill to disk (crashing performance)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
